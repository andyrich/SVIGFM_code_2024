{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171b255-b8bb-4474-a8d7-2d0dd6971643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyemu\n",
    "import conda_scripts.load_datasets as lsd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import conda_scripts\n",
    "import forward_run\n",
    "import matplotlib.pyplot as plt\n",
    "import conda_scripts.plot_help as ph\n",
    "from conda_scripts import sv_budget\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import flopy\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb6ed4-ac40-454a-89d8-93206005eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = lsd.model_info.get_mod('son', True)\n",
    "workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eccc0a-86e5-411d-a9b4-3def2a9e362e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18f553-1d56-46da-954d-73840d38feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = 'postprocess'\n",
    "fold =  'pestaws_v1'\n",
    "\n",
    "out_folder = os.path.join(main, fold)\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder, exist_ok =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc559c-4440-4fff-93df-2cb4e4c16d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d6186-a053-48a2-83ed-2499bb7edb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = conda_scripts.sv_budget.load_sv_model.get_model(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6b756-fc0c-4883-b26e-16cbc81ea230",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1881adcb-6c0e-4c01-ae08-bdb5fd9e7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flopy.modflow.mfhob as hfb\n",
    "import flopy.modflow.mfhyd as hyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef832c59-2dc4-46c5-8f79-300821ce01a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\GSP\\waterlevel\\GIS\\hydro_experiment\\hydros__v3_SON_allmodmonths_to_20240808\\hydros_predicted_SON.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae3551-66ed-4642-aeef-4b2dfd3e5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query('`Station Name`.str.contains(\"_mod\") == False', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a6985-2fb8-48c8-a2c8-347bba9697ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4fa72-7e5d-4fd5-b845-ad516d3c73e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['Station Name', 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd48f6e-43de-4c3e-8aa0-65ec3661e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Depth'] = \"Other\"\n",
    "df.loc[df.Shallow,'Depth'] = \"Shallow\"\n",
    "df.loc[df.Deep,'Depth'] = \"Deep\"\n",
    "\n",
    "df = df.loc[~(df.Depth=='Other')]\n",
    "df.drop_duplicates('Station Name').Depth.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7f695-749b-4fe9-a564-f5208492c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = df.drop_duplicates('Station Name').set_index('Station Name').apply( lambda row: ml.modelgrid.intersect(row['Easting'], row['Northing']),axis = 1)\n",
    "\n",
    "lrc = pd.DataFrame(lrc.to_list(), index = lrc.index, columns=['i','j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f44518-103f-4241-bd89-09c87ab6923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, lrc, left_on = 'Station Name', right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d00390-d3a8-432b-a828-b399c6a921b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"Deep==True | Shallow==True\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0278a-756f-414d-ab3f-256cf466342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45f8b3-27cc-4d82-ba5e-fa088c605613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a12ed-ad8e-4eeb-aa3c-57ee213a08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates =conda_scripts.sv_budget.sv_modflow.get_dates()\n",
    "dates.loc[:,'date'] = dates.date-  pd.offsets.MonthBegin(1)\n",
    "dates.head()\n",
    "dates = dates.astype({'date':'datetime64[ns]'})\n",
    "print(dates.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d111637-9637-4550-aaaf-ec2ba4921509",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = pd.merge(df.astype({'datetime':'datetime64[ns]'}), dates, left_on = 'datetime', right_on = 'date')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99d265-635d-4985-9fd3-31de9462beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = conda_scripts.wiski.wiski.get_stations()\n",
    "stats = stats.loc[:,['station_no', 'station_name']].rename(columns = {'station_name':\"Station Name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495fba26-2ca2-4f9b-813b-07a0a55bb023",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538242a-9d59-437a-8c4c-477510707dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, stats, on = \"Station Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc0e9a1-81dd-4ee0-8fb2-a344ec11e596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0b17c-b10b-4f5d-b7d1-ceab33c256c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add standard deviation to obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adbd09c-d867-43b1-b44b-336d07f11c6b",
   "metadata": {},
   "source": [
    "# export to csv for other users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe080f-a511-4731-891f-22bcb0f248d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.set_index(['Station Name','date','kstp','Depth','i','j',\"Easting\",'Northing']).loc[:,['predicted']].to_csv(os.path.join('..','waterlevel', 'GWLE','gwle_estimates_for_hydobs.csv'), float_format='%.3f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0aa2d-a143-4f40-bb2b-53b2a77d3dc5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "256ff7b2-e743-444f-8da2-b278bbd2b4eb",
   "metadata": {},
   "source": [
    "# [flopy link to hydmod](https://flopy.readthedocs.io/en/latest/source/flopy.modflow.mfhyd.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785df60-310a-4e53-af3e-37621ccc83b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = ml.bas6.ibound.array[0]\n",
    "zone2 = ml.bas6.ibound.array[1]\n",
    "plt.imshow(zone)\n",
    "plt.imshow(zone2)\n",
    "zone = conda_scripts.arich_functions.array2rc(zone,name = 'zone').drop(columns = ['row', 'column'])\n",
    "zone2 = conda_scripts.arich_functions.array2rc(zone2,name = 'zone2').drop(columns = ['row', 'column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00766d-d97d-443d-a896-2236a1b1f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata = df.copy()\n",
    "obsdata = obsdata.drop_duplicates(\"Station Name\")\n",
    "obsdata = pd.merge(obsdata, zone, on = ['i','j'])\n",
    "print(obsdata.shape)\n",
    "obsdata = pd.merge(obsdata, zone2, on = ['i','j'])\n",
    "print(obsdata.shape)\n",
    "obsdata.loc[:,'xl'] ,obsdata.loc[:,'yl'] = ml.modelgrid.get_local_coords(obsdata.Easting.values, obsdata.Northing.values)\n",
    "obsdata.loc[:,['pckg','arr','intyp', 'klay']] = ['BAS','HD',\"C\",-111]\n",
    "obsdata.loc[obsdata.Shallow,'klay'] = 0\n",
    "obsdata.loc[obsdata.Deep,'klay'] = 3\n",
    "#set layer to layer 2 where zone/ibound ==0\n",
    "obsdata.loc[obsdata.zone==0,'klay'] = 1\n",
    "# remove locations no in ibound2\n",
    "obsdata = obsdata.loc[obsdata.zone2!=0,:]\n",
    "obsdata = obsdata.loc[obsdata.klay>=0]\n",
    "obsdata = obsdata.loc[:,['pckg','arr','intyp', 'klay', 'xl', 'yl','Station Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27552ac5-c8b1-4061-8094-b087942ce24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata.klay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2210a66-a1ad-4763-9782-fddb574cbb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7976915c-1c9f-4aa7-bb53-935d85309b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80f25e-5564-468f-be72-f1951c35832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyd.ModflowHyd.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f2294-a665-4897-889b-bce761b58d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.remove_package('HYD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574f5090-1ffa-4f11-b894-375b263e713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.model_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e30c1f-50c8-4a2e-b404-c36f6d81ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = hyd.ModflowHyd(ml, \n",
    "           nhyd=obsdata.shape[0], \n",
    "           ihydun=None, \n",
    "           hydnoh=-9999.0, \n",
    "           # obsdata=[['BAS', 'HD', 'C', 0, 0.0, 0.0, 'HOBS1']], \n",
    "                          obsdata=obsdata.values, \n",
    "           extension=['hyd', 'hyd.bin'], \n",
    "           unitnumber=70, \n",
    "           filenames=\"hyd.hyd\")\n",
    "hello.write_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3cf6e6-e475-4dd8-a828-9aedd8b0caea",
   "metadata": {},
   "source": [
    "# load hydmod output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ea7aa-b5c8-45a5-8ff0-48d25de09e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aa340b-b431-44ee-aa63-b98343367493",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata.drop_duplicates('Station Name').to_csv(os.path.join('..','waterlevel', 'GWLE','hydobs_locations.csv'), float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a7a23-e437-4441-9d7b-09968f593cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import forward_run\n",
    "from importlib import reload\n",
    "reload(forward_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c9eb9-9387-4e57-913c-9d25b4e8f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_run.run_all_hyd_obs(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089bbbcf-a8fb-43fd-8578-61a45e77bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = forward_run.load_hydobs(workspace)\n",
    "s = forward_run.create_diff_for_hydobs(s,numper_diff=5)\n",
    "s = forward_run.down_sample_hydobs(s, numper_diff=5, keep_every=4)\n",
    "s = forward_run.create_obs_from_hyd(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33dffa-2f6d-4653-b049-7f7a95645a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = s.set_index('year').loc[:,['month','Son0001']].set_index('month', append = True).unstack()\n",
    "f = f.where(f.isnull(),1)\n",
    "f = f.droplevel(0,1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb228e7-f8e6-48ba-baf6-36faa4d71f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d256f8-b266-492c-9ca7-becace8eb5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Index= ['aaa', 'bbb', 'ccc', 'ddd', 'eee']\n",
    "# Cols = ['A', 'B', 'C', 'D']\n",
    "# df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)\n",
    "\n",
    "sns.heatmap(f, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388d85d-3d6e-4f9f-898b-41174cd40e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc17dc9-8be3-47e5-a510-d6248e4e0ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890af05-d8c9-4eab-9b1e-49ca69e1f85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1372eb-f4a0-41ab-9ed9-86b97023d856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6477c-f8d3-403a-9bc2-e8fb1d6642c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a98607-3506-4bf4-8c33-7adfc383ed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b48bde-4296-4736-b623-48a6c0a36d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddc375-e48b-42fb-9bb0-c60ef61f3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hydobs(workspace):\n",
    "    out = flopy.utils.HydmodObs(os.path.join(workspace, 'output', 'SV_hyd.hyd'),)\n",
    "    out = out.get_dataframe(start_datetime='12/1/1969')\n",
    "    out = out.rename(columns = lambda x: x[6:]  if len(x)>12 else x)\n",
    "    out = out.drop(columns = 'totim')\n",
    "\n",
    "    out = out.reindex(pd.date_range('1975-01-01', freq = 'MS', periods = 525))\n",
    "\n",
    "    return out\n",
    "\n",
    "def create_obs_from_hyd(sim):\n",
    "    sim = sim.stack()\n",
    "    sim.index = sim.index.set_names(['Station', 'date'])\n",
    "    sim = sim.swaplevel().to_frame('meas').reset_index()\n",
    "\n",
    "    return sim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d412a-696f-4008-af24-92c2419f8d81",
   "metadata": {},
   "source": [
    "# load hydmod output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322ce47-da2d-4c37-a8d9-84cc84636476",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = flopy.utils.HydmodObs(os.path.join(workspace, 'output', 'SV_hyd.hyd'),)\n",
    "out = out.get_dataframe(start_datetime='12/1/1969')\n",
    "out = out.rename(columns = lambda x: x[6:]  if len(x)>12 else x)\n",
    "out = out.drop(columns = 'totim')\n",
    "display(out.head())\n",
    "display(out.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c57604-d95b-4af9-9662-5d3f6d35493e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc12f3c-6d0d-46bf-9b06-c74957bcef4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc5a353f-8766-48ad-9748-64faea750449",
   "metadata": {},
   "source": [
    "# reshape and shuffle the GWLE data to look like hydmod dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597c864-4e78-45e7-9f73-81b12d7420d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df.loc[:,['Station Name', \"predicted\",'date']].set_index(['date','Station Name']).unstack(1)\n",
    "res.columns = res.columns.droplevel(0)\n",
    "res = res.rename_axis(None, axis=1)\n",
    "res = res.rename_axis(None, axis=0)\n",
    "diff_mat = out - res.reindex_like(out)\n",
    "\n",
    "diff_mat = diff_mat.dropna(how = 'all', axis = 0)\n",
    "\n",
    "diff_mat = diff_mat.loc[:,diff_mat.abs().max().sort_values(ascending = True).index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00345c35-76da-4767-955e-fb5a6edd2daa",
   "metadata": {},
   "source": [
    "# export the GWLE data in format to ingest via pest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181359ce-0110-4f7b-8f37-68411e2e0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwle_diff = forward_run.create_diff_for_hydobs(res,numper_diff=5)\n",
    "gwle_diff = forward_run.down_sample_hydobs(gwle_diff, numper_diff=5, keep_every=4)\n",
    "gwle_diff = forward_run.create_obs_from_hyd(gwle_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcdc82-24b4-4adf-9b91-342cdf002cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gwle_abs = forward_run.create_diff_for_hydobs(res,numper_diff=5)\n",
    "gwle_abs = forward_run.down_sample_hydobs(res, numper_diff=5, keep_every=4)\n",
    "gwle_abs = forward_run.create_obs_from_hyd(gwle_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb83fe4-cc66-4551-81e9-6cadf814dd74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f9506-532c-460d-93ec-a39adcd4b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'there are {gwle_diff.shape[0]} observations in the GWLE observation drawdown elev file')\n",
    "print(f'there are {gwle_abs.shape[0]} observations in the GWLE absolute elev file')\n",
    "\n",
    "f_abs = os.path.join(os.path.join(workspace, \"GWLE_OBS\", 'gwle_asbolute_observed_heads.csv'))\n",
    "print(f\"writing absolute heads to {f_abs}\")\n",
    "f_diff = os.path.join(os.path.join(workspace, \"GWLE_OBS\", 'gwle_drawdown_observed_heads.csv'))\n",
    "print(f\"writing drawdon heads to {f_diff}\")\n",
    "\n",
    "gwle_abs.to_csv(f_abs)\n",
    "gwle_diff.to_csv(f_diff)\n",
    "\n",
    "f_abs = os.path.join('..','waterlevel', 'GWLE','gwle_asbolute_observed_heads.csv')\n",
    "print(f\"writing absolute heads to {f_abs}\")\n",
    "f_diff = os.path.join('..','waterlevel', 'GWLE', 'gwle_drawdown_observed_heads.csv')\n",
    "print(f\"writing drawdon heads to {f_diff}\")\n",
    "\n",
    "\n",
    "gwle_abs.to_csv(f_abs)\n",
    "gwle_diff.to_csv(f_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035c418-4dbd-44af-a91b-dfc089e7866d",
   "metadata": {},
   "source": [
    "# export again the station info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fe947-9b86-4e5b-a940-d737365fe2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf58b57e-5f0a-4975-a908-9accb5029002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49365c68-1eff-41bf-be58-c666613c8201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd91e1c-a6c1-4cf2-9792-59e3d008b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.genfromtxt(os.path.join(ml.model_ws, 'model_arrays', 'zonation_3.csv'), delimiter = ' ')\n",
    "\n",
    "zotther = z.copy()\n",
    "zotther[zotther>8] = 0\n",
    "\n",
    "zones = {i:zotther  for i in range(7) }\n",
    "zones[1] = z\n",
    "plt.imshow(zones[1])\n",
    "\n",
    "z = conda_scripts.arich_functions.array2rc(zones[1],'zone').astype({'zone':int})\n",
    "\n",
    "aliases = {1: 'Bay', 2: 'EastSide', 3: 'SouthCent', 4: 'Kenwood', 5: 'VOM', 6: 'AguaCal',7:'WestSide',8:'CitySon',9:'Highlands'}\n",
    "z.loc[:,'zone'] =z.loc[:,'zone'].replace(aliases)\n",
    "z = z.query(\"zone!=0\")\n",
    "\n",
    "geoms = conda_scripts.arich_functions.get_model_shp(ml.modelgrid, 2226).drop(columns = ['row','col'])\n",
    "\n",
    "z = gpd.GeoDataFrame(pd.merge(z, geoms, on = ['i','j']))\n",
    "zplot = z.dissolve('zone').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea603d5-c334-40d5-88d7-40278cb44800",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (6,8), dpi = 250)\n",
    "ax = plt.subplot(1,1,1, projection = ccrs.epsg(2226))\n",
    "zplot.exterior.plot(ax = ax,  )\n",
    "zplot.plot('zone', ax = ax, alpha =.5  )\n",
    "conda_scripts.plot_help.label_poly(zplot,ax, 'zone',color = 'g', text_color='k') \n",
    "conda_scripts.arich_functions.add_basemaps(ax)\n",
    "ax.set_title('zone names')\n",
    "plt.savefig('map_of_zones_for_PEST.png', dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a1a37-dba2-4ca7-a3d1-7fc45d71f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcounts = pd.read_csv(r\"C:\\GSP\\waterlevel\\GIS\\hydro_experiment\\hydros__v3_SON_allmodmonths_to_20240808\\seasinfo_w_predicted_SON.csv\")\n",
    "vcounts = vcounts.loc[:,'Station Name'].value_counts().to_frame(\"num_meas\")\n",
    "vcounts = vcounts.loc[~vcounts.index.str.contains('mod')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e131e04-2a16-4467-ab13-567326c271fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aacccb-e487-4375-b601-c66bdaaaf56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinfo = pd.merge(df.loc[:,['Station Name', 'station_no', \n",
    "       'Site', 'Easting', 'Northing', 'Latitude',\n",
    "       'Longitude',  'rasterelevation', 'slope',\n",
    "       'Simple_Bou', 'Complete_B', 'isostatic',  'Geol_Krig',\n",
    " \n",
    "      'Depth', 'i', 'j', \n",
    "       ]].drop_duplicates('Station Name'),\n",
    "                  z, on = ['i','j'], how = 'left')\n",
    "dfinfo = dfinfo.drop(columns = ['geometry','row','column'])\n",
    "\n",
    "dfinfo = pd.merge(dfinfo, vcounts,on = 'Station Name' )\n",
    "\n",
    "dfinfo.to_csv(os.path.join(workspace, \"GWLE_OBS\",'gwle_station_info.csv'), float_format='%.3f')\n",
    "\n",
    "\n",
    "dfinfo.to_csv(os.path.join('..','waterlevel', 'GWLE','gwle_station_info.csv'), float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df912c-324e-464f-82a3-87c2a0dba98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a155c9-9bff-4ba9-bc2f-db685b661b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_mat.dropna(how = 'all', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b07b29-863d-4941-a3ee-804d858e65bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043e251-4f43-4b30-b4c5-f3a4df12b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.loc[:,'Station Name'].isin(diff_mat.loc[:,~diff_mat.columns.isin(diff_mat.dropna(how = 'all', axis = 1).columns)].columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85e598-6338-4e9d-9162-5c454ce77d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all of these columns are probably null in the GWLE values')\n",
    "diff_mat.loc[:,~diff_mat.columns.isin(diff_mat.dropna(how = 'all', axis = 1).columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abb5af-1311-4b59-bc43-daf5e6e7497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import helpers\n",
    "from helpers import make_plot\n",
    "reload(helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0f033-8d97-4538-812d-6ad0e02768bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import make_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141d6e6-b46e-42c1-898f-3a395a1b6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for   stat in d:\n",
    "    # print(stat)\n",
    "    row = df.query(f\"`Station Name`=='{stat}'\")\n",
    "    \n",
    "    rowind = row['i'].unique()[0]\n",
    "    column = row['j'].unique()[0]\n",
    "    \n",
    "    x = row['Easting'].unique()[0]\n",
    "    y = row['Northing'].unique()[0]\n",
    "    fig, ax = helpers.make_plot('',x,y)\n",
    "\n",
    "    ax.set_title(stat)\n",
    "    res.loc[:,stat].rename(\"GWLE\").plot(ax = ax, label = \"GWLE\")\n",
    "    out.loc[:,stat].plot(ax = ax ,label = \"OWHM\")\n",
    "    out.loc[:,stat].head(1).plot(ax = ax ,c = 'r', marker = 'o', label = \"Starting\")\n",
    "    ax.legend()\n",
    "    \n",
    "    # lays = row.iloc[[0],:].reset_index().at[0,'mlays']\n",
    "    # lays = ', '.join([str(j+1) for j in lays])\n",
    "    # ax.set_title( \"\".join(row.obsname.unique()[0].split(\"_\")[:-1])  )\n",
    "\n",
    "    ph.yrange_(ax)\n",
    "    ax.grid(True)\n",
    "    print(stat, rowind, column, row.shape,os.path.abspath(os.path.join(out_folder,'hydros', stat+'.png' )))\n",
    "    plt.savefig(os.path.join(out_folder,'hydros', stat+'.png' ))\n",
    "    plt.close(fig)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3ac4d-4830-48d7-9a4e-75eb72ebdc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971eda0-bea6-4f4e-98fd-46bac6a1acaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a63d39-9362-4131-aa88-a66500f309ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64fd46-524e-4b33-9b1a-2f484a3ab0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_csv(input_file, output_file, threshold_x, threshold_y, threshold_z, threshold_a, threshold_b):\n",
    "    \"\"\"\n",
    "    Processes a CSV file based on given criteria.\n",
    "    \n",
    "    Args:\n",
    "    input_file: Path to the input CSV file.\n",
    "    output_file: Path for the output CSV file.\n",
    "    threshold_x: Threshold value for station number SL1 0329.\n",
    "    threshold_y: Threshold value for station number so10330.\n",
    "    threshold_z: Threshold value for station number son 0346.\n",
    "    threshold_a: Threshold value for station number s o n 0549.\n",
    "    threshold_b: Threshold value for station number s o n 0550.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(df.shape)\n",
    "    # Remove rows with specific station numbers\n",
    "    df = df[~df['station_name'].str.contains('Son0067')]\n",
    "    df = df[~df['station_name'].str.contains('Son0079')]\n",
    "    df = df[~df['station_name'].str.contains('Son0085')]\n",
    "    df = df[~df['station_name'].str.contains('Son0346')]\n",
    "    df = df[~df['station_name'].str.contains('Son0082')]\n",
    "    df = df[~df['station_name'].str.contains('Son0097')]\n",
    "    df = df[~df['station_name'].str.contains('Son0130')]\n",
    "    df = df[~df['station_name'].str.contains('Son0148')]\n",
    "    df = df[~df['station_name'].str.contains('Son0216')]\n",
    "    df = df[~df['station_name'].str.contains('Son0220')]\n",
    "    df = df[~df['station_name'].str.contains('Son0221')]\n",
    "    df = df[~df['station_name'].str.contains('Son0223')]\n",
    "    df = df[~df['station_name'].str.contains('Son0231')]\n",
    "    df = df[~df['station_name'].str.contains('Son0233')]\n",
    "    df = df[~df['station_name'].str.contains('Son0247')]\n",
    "    \n",
    "    # Replace values based on station numbers and thresholds\n",
    "    df.loc[(df['station_name'] == 'Son0329') & (df['Manual Measurement'] > threshold_x), 'Manual Measurement'] = np.nan\n",
    "    df.loc[(df['station_name'] == 'Son0330') & (df['Manual Measurement'] < threshold_y), 'Manual Measurement'] = np.nan\n",
    "\n",
    "    df.loc[(df['station_name'] == 'Son0346') & (df['Manual Measurement'] > threshold_z), 'Manual Measurement'] = np.nan\n",
    "    df.loc[(df['station_name'] == 'Son0549') & (df['Manual Measurement'] < threshold_a), 'Manual Measurement'] = np.nan\n",
    "    df.loc[(df['station_name'] == 'Son0550') & (df['Manual Measurement'] < threshold_b), 'Manual Measurement'] = np.nan\n",
    "    \n",
    "    df.loc[(df['station_name'] == 'Son0040') & (df['Manual Measurement'] > 975), 'Manual Measurement'] = np.nan\n",
    "    df.loc[(df['station_name'] == 'Son0185') & (df['Manual Measurement'] > 820), 'Manual Measurement'] = np.nan\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    t = pd.to_datetime(df['Timestamp'], utc=True)\n",
    "    \n",
    "    # Filter data\n",
    "    # Filter data\n",
    "    df = df[~((df['station_name'] == 'Son0330') & (\n",
    "        (t >= pd.to_datetime('2015-01-01', utc=True)) & (df['Manual Measurement'] >= -35)))]\n",
    "\n",
    "\n",
    "    \n",
    "    df = df.dropna(subset = 'Manual Measurement')\n",
    "    \n",
    "    print(df.shape)\n",
    "\n",
    "\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    return df\n",
    "    \n",
    "# Example usage:\n",
    "input_file = 'your_input_file.csv'\n",
    "output_file = 'filtered_data.csv'\n",
    "threshold_x = -2\n",
    "threshold_y = -55\n",
    "threshold_z = 80\n",
    "threshold_a = 60\n",
    "threshold_b = 60\n",
    "\n",
    "input_file = r\"C:\\GSP\\waterlevel\\regression_data\\all_gw_for_surf_2024_05_01.csv\"\n",
    "output_file = r\"C:\\GSP\\waterlevel\\regression_data\\all_gw_for_surf_2024_08_08.csv\"\n",
    "dfal = process_csv(input_file, output_file, threshold_x, threshold_y, threshold_z, threshold_a, threshold_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c842f0-d628-46f8-8c98-fd438bb8e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfal = conda_scripts.utils.load_all_gw_wiski.load_all_gw(download=False,filter_manual=True,outfolder=r\"C:\\GSP\\waterlevel\\regression_data\", outfile=\"all_gw_for_surf_2024_08_08.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b0dfd-ccb2-4517-a396-24240fda8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for stat in ['Son0085','Son0329',\n",
    "'Son0330',\n",
    "'Son0346',\n",
    "'Son0549',\n",
    "'Son0550']:\n",
    "        fig, ax = plt.subplots()\n",
    "        cdf= dfal.query(f\"station_name=='{stat}'\")\n",
    "        for t, ddd in cdf.groupby('Param_reclass'):\n",
    "\n",
    "            ddd.plot.scatter(ax = ax, x = 'Timestamp', y = 'Manual Measurement', label = t, legend = True )\n",
    "        ax.set_title(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f29bfb-5aaf-458c-bf2e-763256b1f7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff3cc0-cdc9-4e6c-b7af-d1e0161b9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values based on station numbers and thresholds\n",
    "dfal.loc[(dfal['station_name'] == 'Son0329') ]\n",
    "# df.loc[(df['station_name'] == 'Son0330') & (df['Manual Measurement'] < threshold_y), 'Manual Measurement'] = np.nan\n",
    "# df.loc[(df['station_name'] == 'Son0346') & (df['Manual Measurement'] > threshold_z), 'Manual Measurement'] = np.nan\n",
    "# df.loc[(df['station_name'] == 'Son0549') & (df['Manual Measurement'] < threshold_a), 'Manual Measurement'] = np.nan\n",
    "# df.loc[(df['station_name'] == 'Son0550') & (df['Manual Measurement'] < threshold_b), 'Manual Measurement'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50882bb8-34f1-48a4-a3a0-82caf296319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bad = out.loc[:,out.nunique()==1]\n",
    "bad = list(map(lambda x: x[6:], bad))\n",
    "bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92aa12-602f-491b-a2d9-4ba0cfe94213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba2213-e5ad-4a1d-8b0e-d6bcbc3afa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'measname'] = df.loc[:,'Station Name']+\"_\"+df.loc[:,'kstp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff90f8-bac6-4229-8cac-43a0407ee246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(f\"`Station Name`=='Son0001'\").sort_values('kstp').kstp.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c540cb9-1cc1-45ec-b3cb-6de01d6f9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= df.query(f\"`Station Name`=='Son0001'\").sort_values('kstp')\n",
    "f.loc[f.kstp.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcfdc1e-3a97-4f35-93e5-bee6b3879794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3b0d5-0300-4954-9916-dd33378acc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abca79d-43f8-427f-9a4c-75e328c7b15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbcf638-0d82-4342-ab89-e215aaed6568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81faff-870f-4a26-9af5-9ed448f41770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_string(length=10):\n",
    "    # Define the pool of characters (letters and digits)\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    # Randomly select 'length' characters from the pool\n",
    "    random_string = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return random_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc963c-abf9-4211-8fcd-e9d35521af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dd(ml, station, hds):\n",
    "\n",
    "    q = hds.query(f\"`Station Name`=='{station}'\").sort_values('kstp')\n",
    "    q = q.drop_duplicates('kstp')\n",
    "    # print(q)\n",
    "    hall = []\n",
    "    \n",
    "    for i in range(q.shape[0]-1):\n",
    "        ts = q.iloc[[i,i+1],:].loc[:,['kstp','predicted']].values\n",
    "        wellname = q.iloc[[i],:].loc[:,['measname']].values[0][0]\n",
    "        obsname = q.iloc[[i+1],:].loc[:,['measname']].values[0][0]+'_dd0'\n",
    "        names =  copy.deepcopy([q.iloc[[i],:].loc[:,['measname']].values[0][0]+'_hd1', \n",
    "                                q.iloc[[i+1],:].loc[:,['measname']].values[0][0]+'xxdd0'])\n",
    "        # names = [generate_random_string(length=10),generate_random_string(length=10)]\n",
    "        obsname = copy.deepcopy(wellname+'_hd0')\n",
    "        row = q.i.unique()[0]\n",
    "        column = q.j.unique()[0]\n",
    "        # print(wellname)\n",
    "        print(obsname)\n",
    "        print(names)\n",
    "        h = hfb.HeadObservation(ml, \n",
    "                    tomulth=1.0, \n",
    "                    obsname= q.iloc[[i+1],:].loc[:,['measname']].values[0][0]+'xxhd0', \n",
    "                    layer=0, \n",
    "                    row=row, \n",
    "                    column=column, \n",
    "                    irefsp=-i, \n",
    "                    roff=0.0, \n",
    "                    coff=0.0,\n",
    "                    itt=2,\n",
    "                    tmax=None, \n",
    "                    mlay=None, \n",
    "                    time_series_data=ts, \n",
    "                    names=names)\n",
    "\n",
    "        hall.extend([copy.deepcopy(h)])\n",
    "        \n",
    "    return hall\n",
    "\n",
    "heads = dd(ml, 'Son0001', df)\n",
    "hob = flopy.modflow.ModflowHob(ml, iuhobsv=51, hobdry=-9999.,\n",
    "\n",
    "                               obs_data=heads)\n",
    "hob.write_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c575c3e-5c21-4da1-b6e3-59f04136b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hob.obs_data[0].time_series_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9495a-6d92-479c-bebe-8046bd5fd1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len('SV-F06-01_62')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a13f5-c72e-49ff-92d9-6d906f89f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hfb.HeadObservation(ml, \n",
    "                    tomulth=1.0, \n",
    "                    obsname='HOBS', \n",
    "                    layer=0, \n",
    "                    row=0, \n",
    "                    column=0, \n",
    "                    irefsp=None, \n",
    "                    roff=0.0, \n",
    "                    coff=0.0,\n",
    "                    itt=1,\n",
    "                    tmax=None, \n",
    "                    mlay=None, \n",
    "                    time_series_data=None, \n",
    "                    names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c013c-eec9-4dbb-8c63-202c9b2b1bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a33ce-fddc-41fc-b997-b383f96ffbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c2217-2439-4c09-b81b-9c204bdf33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.modelgrid.get_local_coords(obsdata.Easting, obsdata.Northing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc8969-22bb-4d3c-9bb0-93ab6df7f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "flopy.utils.HydmodObs(os.path.join(workspace, 'output', 'SV_hyd.hyd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a78164-aaa2-40c1-b2be-d70768d73413",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(workspace, 'output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3316333-65bd-4064-a221-dc46fe6c3201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
