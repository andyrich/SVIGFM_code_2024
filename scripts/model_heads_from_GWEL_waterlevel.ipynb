{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyemu\n",
    "import conda_scripts.load_datasets as lsd\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import conda_scripts\n",
    "import forward_run\n",
    "import matplotlib.pyplot as plt\n",
    "import conda_scripts.plot_help as ph\n",
    "from conda_scripts import sv_budget\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import flopy\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = lsd.model_info.get_mod('son', True)\n",
    "workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = 'postprocess'\n",
    "fold =  'pestaws_v1'\n",
    "\n",
    "out_folder = os.path.join(main, fold)\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder, exist_ok =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = conda_scripts.sv_budget.load_sv_model.get_model(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flopy.modflow.mfhob as hfb\n",
    "import flopy.modflow.mfhyd as hyd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\GSP\\waterlevel\\GIS\\hydro_experiment\\hydros__v3_SON_allmodmonths_to_20240808\\hydros_predicted_SON.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query('`Station Name`.str.contains(\"_mod\") == False', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['Station Name', 'datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Depth'] = \"Other\"\n",
    "df.loc[df.Shallow,'Depth'] = \"Shallow\"\n",
    "df.loc[df.Deep,'Depth'] = \"Deep\"\n",
    "\n",
    "df = df.loc[~(df.Depth=='Other')]\n",
    "df.drop_duplicates('Station Name').Depth.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = df.drop_duplicates('Station Name').set_index('Station Name').apply( lambda row: ml.modelgrid.intersect(row['Easting'], row['Northing']),axis = 1)\n",
    "\n",
    "lrc = pd.DataFrame(lrc.to_list(), index = lrc.index, columns=['i','j'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, lrc, left_on = 'Station Name', right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"Deep==True | Shallow==True\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates =conda_scripts.sv_budget.sv_modflow.get_dates()\n",
    "dates.loc[:,'date'] = dates.date-  pd.offsets.MonthBegin(1)\n",
    "dates.head()\n",
    "dates = dates.astype({'date':'datetime64[ns]'})\n",
    "print(dates.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = pd.merge(df.astype({'datetime':'datetime64[ns]'}), dates, left_on = 'datetime', right_on = 'date')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = conda_scripts.wiski.wiski.get_stations()\n",
    "stats = stats.loc[:,['station_no', 'station_name']].rename(columns = {'station_name':\"Station Name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, stats, on = \"Station Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add standard deviation to obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# export to csv for other users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.set_index(['Station Name','date','kstp','Depth','i','j',\"Easting\",'Northing']).loc[:,['predicted']].to_csv(os.path.join('..','waterlevel', 'GWLE','gwle_estimates_for_hydobs.csv'), float_format='%.3f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# [flopy link to hydmod](https://flopy.readthedocs.io/en/latest/source/flopy.modflow.mfhyd.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = ml.bas6.ibound.array[0]\n",
    "zone2 = ml.bas6.ibound.array[1]\n",
    "zone = zone+zone2\n",
    "plt.imshow(zone)\n",
    "# plt.figure()\n",
    "# plt.imshow(zone2)\n",
    "zone = conda_scripts.arich_functions.array2rc(zone,name = 'zone').drop(columns = ['row', 'column'])\n",
    "# zone2 = conda_scripts.arich_functions.array2rc(zone2,name = 'zone2').drop(columns = ['row', 'column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata = df.copy()\n",
    "obsdata = obsdata.drop_duplicates(\"Station Name\")\n",
    "obsdata = pd.merge(obsdata, zone, on = ['i','j'])\n",
    "print(obsdata.shape)\n",
    "# obsdata = pd.merge(obsdata, zone2, on = ['i','j'])\n",
    "# print(obsdata.shape)\n",
    "obsdata.loc[:,'xl'] ,obsdata.loc[:,'yl'] = ml.modelgrid.get_local_coords(obsdata.Easting.values, obsdata.Northing.values)\n",
    "obsdata.loc[:,['pckg','arr','intyp', 'klay']] = ['BAS','HD',\"C\",-111]\n",
    "obsdata.loc[obsdata.Shallow,'klay'] = 0\n",
    "obsdata.loc[obsdata.Deep,'klay'] = 3\n",
    "#set layer to layer 1 where zone/ibound ==1 (ie highlands)\n",
    "obsdata.loc[obsdata.zone==1,'klay'] = 0\n",
    "# remove locations no in ibound2\n",
    "# obsdata = obsdata.loc[obsdata.zone2!=0,:]\n",
    "obsdata = obsdata.loc[obsdata.klay>=0]\n",
    "obsdata = obsdata.loc[:,['pckg','arr','intyp', 'klay', 'xl', 'yl','Station Name']]\n",
    "print(obsdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata.klay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyd.ModflowHyd.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.remove_package('HYD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.model_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = hyd.ModflowHyd(ml, \n",
    "           nhyd=obsdata.shape[0], \n",
    "           ihydun=None, \n",
    "           hydnoh=-9999.0, \n",
    "           # obsdata=[['BAS', 'HD', 'C', 0, 0.0, 0.0, 'HOBS1']], \n",
    "                          obsdata=obsdata.values, \n",
    "           extension=['hyd', 'hyd.bin'], \n",
    "           unitnumber=70, \n",
    "           filenames=\"hyd.hyd\")\n",
    "hello.write_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# load hydmod output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata.drop_duplicates('Station Name').to_csv(os.path.join('..','waterlevel', 'GWLE','hydobs_locations.csv'), float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import forward_run\n",
    "from importlib import reload\n",
    "reload(forward_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_run.run_all_hyd_obs(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = forward_run.load_hydobs(workspace)\n",
    "s = forward_run.create_diff_for_hydobs(s,numper_diff=5)\n",
    "s = forward_run.down_sample_hydobs(s, numper_diff=5, keep_every=4)\n",
    "s = forward_run.create_obs_from_hyd(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# creating 10-year rolling average from GWLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigobj = forward_run.load_hydobs(workspace)\n",
    "abs_small = forward_run.down_sample_hydobs(bigobj, numper_diff = 5,keep_every = 4)\n",
    "abs_obs = forward_run.create_obs_from_hyd(abs_small)\n",
    "\n",
    "\n",
    "# rolling observations\n",
    "roll = forward_run.rolling_mean(bigobj,nyears=10)\n",
    "roll_obs = forward_run.create_obs_from_hyd(roll)\n",
    "roll_obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[:,'year'] = s.date.dt.year\n",
    "s.loc[:,'month'] = s.date.dt.month\n",
    "f = s.set_index('year').loc[:,['month','Son0001']].set_index('month', append = True).unstack()\n",
    "f = f.where(f.isnull(),1)\n",
    "f = f.droplevel(0,1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Index= ['aaa', 'bbb', 'ccc', 'ddd', 'eee']\n",
    "# Cols = ['A', 'B', 'C', 'D']\n",
    "# df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)\n",
    "\n",
    "sns.heatmap(f, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hydobs(workspace):\n",
    "    out = flopy.utils.HydmodObs(os.path.join(workspace, 'output', 'SV_hyd.hyd'),)\n",
    "    out = out.get_dataframe(start_datetime='12/1/1969')\n",
    "    out = out.rename(columns = lambda x: x[6:]  if len(x)>12 else x)\n",
    "    out = out.drop(columns = 'totim')\n",
    "\n",
    "    out = out.reindex(pd.date_range('1975-01-01', freq = 'MS', periods = 525))\n",
    "\n",
    "    return out\n",
    "\n",
    "def create_obs_from_hyd(sim):\n",
    "    sim = sim.stack()\n",
    "    sim.index = sim.index.set_names(['Station', 'date'])\n",
    "    sim = sim.swaplevel().to_frame('meas').reset_index()\n",
    "\n",
    "    return sim\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "# load hydmod output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = flopy.utils.HydmodObs(os.path.join(workspace, 'output', 'SV_hyd.hyd'),)\n",
    "out = out.get_dataframe(start_datetime='12/1/1969')\n",
    "out = out.rename(columns = lambda x: x[6:]  if len(x)>12 else x)\n",
    "out = out.drop(columns = 'totim')\n",
    "display(out.head())\n",
    "display(out.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(forward_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "# reshape and shuffle the GWLE data to look like hydmod dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df.loc[:,['Station Name', \"predicted\",'date']].set_index(['date','Station Name']).unstack(1)\n",
    "res.columns = res.columns.droplevel(0)\n",
    "res = res.rename_axis(None, axis=1)\n",
    "res = res.rename_axis(None, axis=0)\n",
    "diff_mat = out - res.reindex_like(out)\n",
    "\n",
    "diff_mat = diff_mat.dropna(how = 'all', axis = 0)\n",
    "\n",
    "diff_mat = diff_mat.loc[:,diff_mat.abs().max().sort_values(ascending = True).index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "# export the GWLE data in format to ingest via pest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwle_diff = forward_run.create_diff_for_hydobs(res,numper_diff=5)\n",
    "gwle_diff = forward_run.down_sample_hydobs(gwle_diff, numper_diff=5, keep_every=4)\n",
    "gwle_diff = forward_run.create_obs_from_hyd(gwle_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gwle_abs = forward_run.create_diff_for_hydobs(res,numper_diff=5)\n",
    "gwle_abs = forward_run.down_sample_hydobs(res, numper_diff=5, keep_every=4)\n",
    "gwle_abs = forward_run.create_obs_from_hyd(gwle_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rolling 18month\n",
    "roll_short = forward_run.rolling_mean(res,nyears = None, nmonths=18)\n",
    "roll_short_obs = forward_run.create_obs_from_hyd(roll_short)\n",
    "roll_short_obs.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling observations\n",
    "roll = forward_run.rolling_mean(res,nyears=8, nmonths = None )\n",
    "roll_obs = forward_run.create_obs_from_hyd(roll)\n",
    "roll_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forward_run.rolling_mean(res, nyears = 8, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_run.rolling_mean(res, nmonths = 18,nyears = None).tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.date_range(ml.dis.start_datetime,periods = ml.dis.nper, freq = 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'there are {gwle_diff.shape[0]} observations in the GWLE observation drawdown elev file')\n",
    "print(f'there are {gwle_abs.shape[0]} observations in the GWLE absolute elev file')\n",
    "print(f'there are {roll_obs.shape[0]} observations in the GWLE observation rolling elev file')\n",
    "print(f'there are {roll_short_obs.shape[0]} observations in the GWLE observation rolling 18month elev file\\n')\n",
    "\n",
    "\n",
    "f_abs = os.path.join(os.path.join(workspace, \"GWLE_OBS\", 'gwle_asbolute_observed_heads.csv'))\n",
    "print(f\"writing absolute heads to {f_abs}\")\n",
    "f_diff = os.path.join(os.path.join(workspace, \"GWLE_OBS\", 'gwle_drawdown_observed_heads.csv'))\n",
    "print(f\"writing drawdon heads to {f_diff}\")\n",
    "f_roll = os.path.join(os.path.join(workspace, \"GWLE_OBS\", 'gwle_rolling_observed_heads.csv'))\n",
    "print(f\"writing rolling heads to {f_roll}\")\n",
    "f_roll_short = os.path.join(os.path.join(workspace, \"GWLE_OBS\", 'gwle_rolling_18month_observed_heads.csv'))\n",
    "print(f\"writing rolling heads to {f_roll_short}\")\n",
    "\n",
    "gwle_abs.to_csv(f_abs)\n",
    "gwle_diff.to_csv(f_diff)\n",
    "roll_obs.to_csv(f_roll)\n",
    "roll_short_obs.to_csv(f_roll_short)\n",
    "\n",
    "f_abs = os.path.join('..','waterlevel', 'GWLE','gwle_asbolute_observed_heads.csv')\n",
    "print(f\"writing absolute heads to {f_abs}\")\n",
    "f_diff = os.path.join('..','waterlevel', 'GWLE', 'gwle_drawdown_observed_heads.csv')\n",
    "print(f\"writing drawdon heads to {f_diff}\")\n",
    "f_roll = os.path.join('..','waterlevel', 'GWLE', 'gwle_rolling_observed_heads.csv')\n",
    "print(f\"writing f_roll heads to {f_roll}\")\n",
    "\n",
    "f_roll_short = os.path.join(os.path.join('..', 'waterlevel',\"GWLE\", 'gwle_rolling_18month_observed_heads.csv'))\n",
    "print(f\"writing rolling heads to {f_roll_short}\")\n",
    "\n",
    "gwle_abs.to_csv(f_abs)\n",
    "gwle_diff.to_csv(f_diff)\n",
    "roll_obs.to_csv(f_roll)\n",
    "roll_short_obs.to_csv(f_roll_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "outf = os.path.join('..','waterlevel','hydros')\n",
    "os.makedirs(outf,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "for n,stat in gwle_abs.groupby('Station'):\n",
    "    ax = stat.plot(x = 'date', y='meas', label = 'GWLE',marker = '.')\n",
    "    roll_obs.query(f\"Station=='{n}'\").plot(x = 'date', y='meas', ax =ax, marker = 's' , mfc = 'w', label = 'GWLE - 10-Year')\n",
    "    roll_short_obs.query(f\"Station=='{n}'\").plot(x = 'date', y='meas', ax =ax, marker = 'o', mfc = 'k', label = 'GWLE - 18-Month ')\n",
    "    \n",
    "    # Set major ticks to every 5 years starting at 1970\n",
    "    # ax.xaxis.set_major_locator(mdates.YearLocator(5))  # Every 5 years\n",
    "    # ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))  # Format ticks as years\n",
    "    ax.set_title(n); ax.grid(True)\n",
    "    # Set x-axis limit to ensure it starts from 1970\n",
    "    plt.xlim(pd.Timestamp('1970-01-01'), pd.Timestamp('2020-01-01'))\n",
    "    # Rotate and align the tick labels\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    conda_scripts.plot_help.yrange_(ax)\n",
    "    plt.savefig(os.path.join(outf, n+'.png'), dpi = 250, bbox_inches = \"tight\")\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "# export again the station info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.genfromtxt(os.path.join(ml.model_ws, 'model_arrays', 'zonation_3.csv'), delimiter = ' ')\n",
    "\n",
    "zotther = z.copy()\n",
    "zotther[zotther>8] = 0\n",
    "\n",
    "zones = {i:zotther  for i in range(7) }\n",
    "zones[1] = z\n",
    "plt.imshow(zones[1])\n",
    "\n",
    "z = conda_scripts.arich_functions.array2rc(zones[1],'zone').astype({'zone':int})\n",
    "\n",
    "aliases = {1: 'Bay', 2: 'EastSide', 3: 'SouthCent', 4: 'Kenwood', 5: 'VOM', 6: 'AguaCal',7:'WestSide',8:'CitySon',9:'Highlands'}\n",
    "z.loc[:,'zone'] =z.loc[:,'zone'].replace(aliases)\n",
    "z = z.query(\"zone!=0\")\n",
    "\n",
    "geoms = conda_scripts.arich_functions.get_model_shp(ml.modelgrid, 2226).drop(columns = ['row','col'])\n",
    "\n",
    "z = gpd.GeoDataFrame(pd.merge(z, geoms, on = ['i','j']))\n",
    "zplot = z.dissolve('zone').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (6,8), dpi = 250)\n",
    "ax = plt.subplot(1,1,1, projection = ccrs.epsg(2226))\n",
    "zplot.exterior.plot(ax = ax,  )\n",
    "zplot.plot('zone', ax = ax, alpha =.5  )\n",
    "conda_scripts.plot_help.label_poly(zplot,ax, 'zone',color = 'g', text_color='k') \n",
    "conda_scripts.arich_functions.add_basemaps(ax)\n",
    "ax.set_title('zone names')\n",
    "plt.savefig('map_of_zones_for_PEST.png', dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcounts = pd.read_csv(r\"C:\\GSP\\waterlevel\\GIS\\hydro_experiment\\hydros__v3_SON_allmodmonths_to_20240808\\seasinfo_w_predicted_SON.csv\")\n",
    "vcounts = vcounts.loc[:,'Station Name'].value_counts().to_frame(\"num_meas\")\n",
    "vcounts = vcounts.loc[~vcounts.index.str.contains('mod')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_hydros_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinfo = pd.merge(df.loc[:,['Station Name', 'station_no', \n",
    "       'Site', 'Easting', 'Northing', 'Latitude',\n",
    "       'Longitude',  'rasterelevation', 'slope',\n",
    "       'Simple_Bou', 'Complete_B', 'isostatic',  'Geol_Krig',\n",
    " \n",
    "      'Depth', 'i', 'j', \n",
    "       ]].drop_duplicates('Station Name'),\n",
    "                  z, on = ['i','j'], how = 'left')\n",
    "dfinfo = dfinfo.drop(columns = ['geometry','row','column'])\n",
    "\n",
    "dfinfo = pd.merge(dfinfo, vcounts,on = 'Station Name' )\n",
    "\n",
    "dfinfo.to_csv(os.path.join(workspace, \"GWLE_OBS\",'gwle_station_info.csv'), float_format='%.3f')\n",
    "\n",
    "\n",
    "dfinfo.to_csv(os.path.join('..','waterlevel', 'GWLE','gwle_station_info.csv'), float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.loc[:,'Station Name'].isin(diff_mat.loc[:,~diff_mat.columns.isin(diff_mat.dropna(how = 'all', axis = 1).columns)].columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('all of these columns are probably null in the GWLE values')\n",
    "diff_mat.loc[:,~diff_mat.columns.isin(diff_mat.dropna(how = 'all', axis = 1).columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import helpers\n",
    "from helpers import make_plot\n",
    "reload(helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import make_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for   stat in d:\n",
    "    # print(stat)\n",
    "    row = df.query(f\"`Station Name`=='{stat}'\")\n",
    "    \n",
    "    rowind = row['i'].unique()[0]\n",
    "    column = row['j'].unique()[0]\n",
    "    \n",
    "    x = row['Easting'].unique()[0]\n",
    "    y = row['Northing'].unique()[0]\n",
    "    fig, ax = helpers.make_plot('',x,y)\n",
    "\n",
    "    ax.set_title(stat)\n",
    "    res.loc[:,stat].rename(\"GWLE\").plot(ax = ax, label = \"GWLE\")\n",
    "    out.loc[:,stat].plot(ax = ax ,label = \"OWHM\")\n",
    "    out.loc[:,stat].head(1).plot(ax = ax ,c = 'r', marker = 'o', label = \"Starting\")\n",
    "    ax.legend()\n",
    "    \n",
    "    # lays = row.iloc[[0],:].reset_index().at[0,'mlays']\n",
    "    # lays = ', '.join([str(j+1) for j in lays])\n",
    "    # ax.set_title( \"\".join(row.obsname.unique()[0].split(\"_\")[:-1])  )\n",
    "\n",
    "    ph.yrange_(ax)\n",
    "    ax.grid(True)\n",
    "    print(stat, rowind, column, row.shape,os.path.abspath(os.path.join(out_folder,'hydros', stat+'.png' )))\n",
    "    plt.savefig(os.path.join(out_folder,'hydros', stat+'.png' ))\n",
    "    plt.close(fig)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_csv(input_file, output_file, threshold_x, threshold_y, threshold_z, threshold_a, threshold_b):\n",
    "    \"\"\"\n",
    "    Processes a CSV file based on given criteria.\n",
    "    \n",
    "    Args:\n",
    "    input_file: Path to the input CSV file.\n",
    "    output_file: Path for the output CSV file.\n",
    "    threshold_x: Threshold value for station number SL1 0329.\n",
    "    threshold_y: Threshold value for station number so10330.\n",
    "    threshold_z: Threshold value for station number son 0346.\n",
    "    threshold_a: Threshold value for station number s o n 0549.\n",
    "    threshold_b: Threshold value for station number s o n 0550.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(df.shape)\n",
    "    # Remove rows with specific station numbers\n",
    "    df = df[~df['station_name'].str.contains('Son0067')]\n",
    "    df = df[~df['station_name'].str.contains('Son0079')]\n",
    "    df = df[~df['station_name'].str.contains('Son0085')]\n",
    "    df = df[~df['station_name'].str.contains('Son0346')]\n",
    "    df = df[~df['station_name'].str.contains('Son0082')]\n",
    "    df = df[~df['station_name'].str.contains('Son0097')]\n",
    "    df = df[~df['station_name'].str.contains('Son0130')]\n",
    "    df = df[~df['station_name'].str.contains('Son0148')]\n",
    "    df = df[~df['station_name'].str.contains('Son0216')]\n",
    "    df = df[~df['station_name'].str.contains('Son0220')]\n",
    "    df = df[~df['station_name'].str.contains('Son0221')]\n",
    "    df = df[~df['station_name'].str.contains('Son0223')]\n",
    "    df = df[~df['station_name'].str.contains('Son0231')]\n",
    "    df = df[~df['station_name'].str.contains('Son0233')]\n",
    "    df = df[~df['station_name'].str.contains('Son0247')]\n",
    "    \n",
    "    # Replace values based on station numbers and thresholds\n",
    "    df.loc[(df['station_name'] == 'Son0329') & (df['Manual Measurement'] > threshold_x), 'Manual Measurement'] = np.nan\n",
    "    df.loc[(df['station_name'] == 'Son0330') & (df['Manual Measurement'] < threshold_y), 'Manual Measurement'] = np.nan\n",
    "\n",
    "    df.loc[(df['station_name'] == 'Son0346') & (df['Manual Measurement'] > threshold_z), 'Manual Measurement'] = np.nan\n",
    "    df.loc[(df['station_name'] == 'Son0549') & (df['Manual Measurement'] < threshold_a), 'Manual Measurement'] = np.nan\n",
    "    df.loc[(df['station_name'] == 'Son0550') & (df['Manual Measurement'] < threshold_b), 'Manual Measurement'] = np.nan\n",
    "    \n",
    "    df.loc[(df['station_name'] == 'Son0040') & (df['Manual Measurement'] > 975), 'Manual Measurement'] = np.nan\n",
    "    df.loc[(df['station_name'] == 'Son0185') & (df['Manual Measurement'] > 820), 'Manual Measurement'] = np.nan\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    t = pd.to_datetime(df['Timestamp'], utc=True)\n",
    "    \n",
    "    # Filter data\n",
    "    # Filter data\n",
    "    df = df[~((df['station_name'] == 'Son0330') & (\n",
    "        (t >= pd.to_datetime('2015-01-01', utc=True)) & (df['Manual Measurement'] >= -35)))]\n",
    "\n",
    "\n",
    "    \n",
    "    df = df.dropna(subset = 'Manual Measurement')\n",
    "    \n",
    "    print(df.shape)\n",
    "\n",
    "\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    return df\n",
    "    \n",
    "# Example usage:\n",
    "input_file = 'your_input_file.csv'\n",
    "output_file = 'filtered_data.csv'\n",
    "threshold_x = -2\n",
    "threshold_y = -55\n",
    "threshold_z = 80\n",
    "threshold_a = 60\n",
    "threshold_b = 60\n",
    "\n",
    "input_file = r\"C:\\GSP\\waterlevel\\regression_data\\all_gw_for_surf_2024_05_01.csv\"\n",
    "output_file = r\"C:\\GSP\\waterlevel\\regression_data\\all_gw_for_surf_2024_08_08.csv\"\n",
    "dfal = process_csv(input_file, output_file, threshold_x, threshold_y, threshold_z, threshold_a, threshold_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfal = conda_scripts.utils.load_all_gw_wiski.load_all_gw(download=False,filter_manual=True,outfolder=r\"C:\\GSP\\waterlevel\\regression_data\", outfile=\"all_gw_for_surf_2024_08_08.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for stat in ['Son0085','Son0329',\n",
    "'Son0330',\n",
    "'Son0346',\n",
    "'Son0549',\n",
    "'Son0550']:\n",
    "        fig, ax = plt.subplots()\n",
    "        cdf= dfal.query(f\"station_name=='{stat}'\")\n",
    "        for t, ddd in cdf.groupby('Param_reclass'):\n",
    "\n",
    "            ddd.plot.scatter(ax = ax, x = 'Timestamp', y = 'Manual Measurement', label = t, legend = True )\n",
    "        ax.set_title(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values based on station numbers and thresholds\n",
    "dfal.loc[(dfal['station_name'] == 'Son0329') ]\n",
    "# df.loc[(df['station_name'] == 'Son0330') & (df['Manual Measurement'] < threshold_y), 'Manual Measurement'] = np.nan\n",
    "# df.loc[(df['station_name'] == 'Son0346') & (df['Manual Measurement'] > threshold_z), 'Manual Measurement'] = np.nan\n",
    "# df.loc[(df['station_name'] == 'Son0549') & (df['Manual Measurement'] < threshold_a), 'Manual Measurement'] = np.nan\n",
    "# df.loc[(df['station_name'] == 'Son0550') & (df['Manual Measurement'] < threshold_b), 'Manual Measurement'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bad = out.loc[:,out.nunique()==1]\n",
    "bad = list(map(lambda x: x[6:], bad))\n",
    "bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'measname'] = df.loc[:,'Station Name']+\"_\"+df.loc[:,'kstp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(f\"`Station Name`=='Son0001'\").sort_values('kstp').kstp.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= df.query(f\"`Station Name`=='Son0001'\").sort_values('kstp')\n",
    "f.loc[f.kstp.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_string(length=10):\n",
    "    # Define the pool of characters (letters and digits)\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    # Randomly select 'length' characters from the pool\n",
    "    random_string = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return random_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dd(ml, station, hds):\n",
    "\n",
    "    q = hds.query(f\"`Station Name`=='{station}'\").sort_values('kstp')\n",
    "    q = q.drop_duplicates('kstp')\n",
    "    # print(q)\n",
    "    hall = []\n",
    "    \n",
    "    for i in range(q.shape[0]-1):\n",
    "        ts = q.iloc[[i,i+1],:].loc[:,['kstp','predicted']].values\n",
    "        wellname = q.iloc[[i],:].loc[:,['measname']].values[0][0]\n",
    "        obsname = q.iloc[[i+1],:].loc[:,['measname']].values[0][0]+'_dd0'\n",
    "        names =  copy.deepcopy([q.iloc[[i],:].loc[:,['measname']].values[0][0]+'_hd1', \n",
    "                                q.iloc[[i+1],:].loc[:,['measname']].values[0][0]+'xxdd0'])\n",
    "        # names = [generate_random_string(length=10),generate_random_string(length=10)]\n",
    "        obsname = copy.deepcopy(wellname+'_hd0')\n",
    "        row = q.i.unique()[0]\n",
    "        column = q.j.unique()[0]\n",
    "        # print(wellname)\n",
    "        print(obsname)\n",
    "        print(names)\n",
    "        h = hfb.HeadObservation(ml, \n",
    "                    tomulth=1.0, \n",
    "                    obsname= q.iloc[[i+1],:].loc[:,['measname']].values[0][0]+'xxhd0', \n",
    "                    layer=0, \n",
    "                    row=row, \n",
    "                    column=column, \n",
    "                    irefsp=-i, \n",
    "                    roff=0.0, \n",
    "                    coff=0.0,\n",
    "                    itt=2,\n",
    "                    tmax=None, \n",
    "                    mlay=None, \n",
    "                    time_series_data=ts, \n",
    "                    names=names)\n",
    "\n",
    "        hall.extend([copy.deepcopy(h)])\n",
    "        \n",
    "    return hall\n",
    "\n",
    "heads = dd(ml, 'Son0001', df)\n",
    "hob = flopy.modflow.ModflowHob(ml, iuhobsv=51, hobdry=-9999.,\n",
    "\n",
    "                               obs_data=heads)\n",
    "hob.write_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "hob.obs_data[0].time_series_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "len('SV-F06-01_62')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = hfb.HeadObservation(ml, \n",
    "                    tomulth=1.0, \n",
    "                    obsname='HOBS', \n",
    "                    layer=0, \n",
    "                    row=0, \n",
    "                    column=0, \n",
    "                    irefsp=None, \n",
    "                    roff=0.0, \n",
    "                    coff=0.0,\n",
    "                    itt=1,\n",
    "                    tmax=None, \n",
    "                    mlay=None, \n",
    "                    time_series_data=None, \n",
    "                    names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.modelgrid.get_local_coords(obsdata.Easting, obsdata.Northing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "flopy.utils.HydmodObs(os.path.join(workspace, 'output', 'SV_hyd.hyd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(workspace, 'output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
